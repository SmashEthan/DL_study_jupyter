{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "pandas.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 0,
        "id": "jrqQCphBSDnM"
      },
      "source": [
        "# Data Preprocessing\n",
        ":label:`sec_pandas`\n",
        "\n",
        "So far we have introduced a variety of techniques for manipulating data that are already stored in tensors.\n",
        "To apply deep learning to solving real-world problems,\n",
        "we often begin with preprocessing raw data, rather than those nicely prepared data in the tensor format.\n",
        "Among popular data analytic tools in Python, the `pandas` package is commonly used.\n",
        "Like many other extension packages in the vast ecosystem of Python,\n",
        "`pandas` can work together with tensors.\n",
        "So, we will briefly walk through steps for preprocessing raw data with `pandas`\n",
        "and converting them into the tensor format.\n",
        "We will cover more data preprocessing techniques in later chapters.\n",
        "\n",
        "## Reading the Dataset\n",
        "\n",
        "As an example,\n",
        "we begin by (**creating an artificial dataset that is stored in a\n",
        "csv (comma-separated values) file**)\n",
        "`../data/house_tiny.csv`. Data stored in other\n",
        "formats may be processed in similar ways.\n",
        "\n",
        "Below we write the dataset row by row into a csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 1,
        "tab": [
          "pytorch"
        ],
        "id": "Lxc8YbPfSDnO"
      },
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
        "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
        "    f.write('2,NA,106000\\n')\n",
        "    f.write('4,NA,178100\\n')\n",
        "    f.write('NA,NA,140000\\n')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 2,
        "id": "yAcRqmuISDnO"
      },
      "source": [
        "To [**load the raw dataset from the created csv file**],\n",
        "we import the `pandas` package and invoke the `read_csv` function.\n",
        "This dataset has four rows and three columns, where each row describes the number of rooms (\"NumRooms\"), the alley type (\"Alley\"), and the price (\"Price\") of a house.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 3,
        "tab": [
          "pytorch"
        ],
        "id": "iZax_ThXSDnP",
        "outputId": "b3e2397b-08c1-482e-fdc1-9684b343a03f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If pandas is not installed, just uncomment the following line:\n",
        "# !pip install pandas\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 4,
        "id": "5Nzc2meESDnP"
      },
      "source": [
        "## Handling Missing Data\n",
        "\n",
        "Note that \"NaN\" entries are missing values.\n",
        "To handle missing data, typical methods include *imputation* and *deletion*,\n",
        "where imputation replaces missing values with substituted ones,\n",
        "while deletion ignores missing values. Here we will consider imputation.\n",
        "\n",
        "By integer-location based indexing (`iloc`), we split `data` into `inputs` and `outputs`,\n",
        "where the former takes the first two columns while the latter only keeps the last column.\n",
        "For numerical values in `inputs` that are missing,\n",
        "we [**replace the \"NaN\" entries with the mean value of the same column.**]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 5,
        "tab": [
          "pytorch"
        ],
        "id": "UofxHcIHSDnQ",
        "outputId": "7f75d82a-7b2a-4f8d-e515-65426d460cc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
        "inputs = inputs.fillna(inputs.mean())\n",
        "print(inputs)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 6,
        "id": "qyR3-fZCSDnQ"
      },
      "source": [
        "[**For categorical or discrete values in `inputs`, we consider \"NaN\" as a category.**]\n",
        "Since the \"Alley\" column only takes two types of categorical values \"Pave\" and \"NaN\",\n",
        "`pandas` can automatically convert this column to two columns \"Alley_Pave\" and \"Alley_nan\".\n",
        "A row whose alley type is \"Pave\" will set values of \"Alley_Pave\" and \"Alley_nan\" to 1 and 0.\n",
        "A row with a missing alley type will set their values to 0 and 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 7,
        "tab": [
          "pytorch"
        ],
        "id": "o3jw7P1oSDnQ",
        "outputId": "5f938427-52dc-4a93-aba9-22a60815bfce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "print(inputs)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 8,
        "id": "9qpGs7jUSDnR"
      },
      "source": [
        "## Conversion to the Tensor Format\n",
        "\n",
        "Now that [**all the entries in `inputs` and `outputs` are numerical, they can be converted to the tensor format.**]\n",
        "Once data are in this format, they can be further manipulated with those tensor functionalities that we have introduced in :numref:`sec_ndarray`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "origin_pos": 10,
        "tab": [
          "pytorch"
        ],
        "id": "9PjKAKvwSDnR",
        "outputId": "45ddb94d-1151-445b-8309-751963e457a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "\n",
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X, y"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 12,
        "id": "QhDG8E2SSDnR"
      },
      "source": [
        "## Summary\n",
        "\n",
        "* Like many other extension packages in the vast ecosystem of Python, `pandas` can work together with tensors.\n",
        "* Imputation and deletion can be used to handle missing data.\n",
        "\n",
        "\n",
        "## Exercises\n",
        "\n",
        "Create a raw dataset with more rows and columns.\n",
        "\n",
        "1. Delete the column with the most missing values.\n",
        "2. Convert the preprocessed dataset to the tensor format.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "origin_pos": 14,
        "tab": [
          "pytorch"
        ],
        "id": "C-BZYw1iSDnS"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/29)\n"
      ]
    }
  ]
}